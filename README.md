# Детектор логотипа Т-Банка на изображениях

Этот проект представляет собой end-to-end решение для задачи детекции объектов. Финальный продукт — это REST API сервис, упакованный в Docker-контейнер, который способен обнаруживать новый логотип Т-Банка на загружаемых изображениях и возвращать его координаты.

## 1. Постановка задачи

Основной целью проекта являлась разработка системы, способной в автоматическом режиме находить на изображениях логотип "Т-Банка". Логотип представляет собой стилизованную букву "Т" внутри геральдического щита.

**Ключевые требования и ограничения:**
- **Задача:** Детекция объектов (возврат координат bounding box).
- **Целевой объект:** Новый логотип "Т-Банка", игнорируя старый герб "Тинькофф".
- **Исходные данные:** Неразмеченный датасет из ~30,000 изображений, содержащий как фотографии с логотипом в различных условиях, так и без него.
- **Ограничения:**
    - Время обработки: не более 10 секунд на изображение.
    - Оборудование: возможность запуска на GPU с 16GB VRAM (уровня NVIDIA T4).
    - Формат решения: REST API в Docker-контейнере.

## 2. Zero-Shot разметка и выбор предобученной модели

Поскольку ручная разметка 30,000 изображений — это трудоемкий и долгий процесс, было принято решение использовать **Zero-Shot подход** для получения первичной, "черновой" разметки.

В качестве базовой модели была выбрана **Grounding DINO** (`IDEA-Research/grounding-dino-base`). Эта модель способна детектировать объекты на изображении по их текстовому описанию (промпту), не требуя предварительного обучения на конкретных примерах целевого объекта. Это позволило быстро обработать весь неразмеченный датасет и получить первоначальный набор аннотаций.

## 3. Кластеризация и анализ результатов

После получения ~4000 автоматических детекций был проведен их анализ для оценки качества работы Zero-Shot подхода. Все найденные объекты (вырезанные из изображений по предсказанным координатам) были кластеризованы.

**Процесс кластеризации:**
1.  **Извлечение признаков:** Каждый вырезанный объект был пропущен через предобученную нейросеть (ResNet50) для получения векторного представления (эмбеддинга).
2.  **Кластеризация:** Полученные векторы были сгруппированы с помощью алгоритма KMeans.

**Результаты анализа:**
Кластеризация показала, что модель Grounding DINO успешно находила объекты, похожие на "щит с буквой", однако первоначальный общий промпт приводил к большому количеству ложных срабатываний (дорожные знаки, другие эмблемы). **Ни одного корректного логотипа Т-Банка найдено не было.**

## 4. Итеративный подбор текстового промпта

Стало очевидно, что качество Zero-Shot разметки напрямую зависит от точности текстового промпта. Было проведено несколько итераций тестирования различных промптов на небольшой выборке для нахождения оптимального варианта.

Сравнивались как общие описания, так и детализированные, с указанием цветов и визуальных атрибутов. Лучший результат показал промпт, сфокусированный на визуальном стиле и контрасте, который хорошо обобщал различные вариации логотипа:
```
"a high-contrast, minimalist shield emblem containing a single capital letter T"
```
Этот промпт позволил значительно повысить точность первичной разметки и стал основой для дальнейшей работы.

## 5. Подготовка данных для ручной доразметки

Автоматически полученные аннотации были сконвертированы из формата JSON в формат **XML Pascal VOC**, который совместим с большинством инструментов для разметки. Для этого был написан специальный Python-скрипт.

## 6. Работа в CVAT

В качестве инструмента для ручной доразметки был выбран **CVAT (Computer Vision Annotation Tool)**. В него были загружены ~4000 изображений, на которых сработала Zero-Shot модель, вместе с соответствующей XML-разметкой.

Процесс доразметки включал в себя:
- **Коррекцию** неточных рамок.
- **Удаление** ложных срабатываний.
- **Добавление** пропущенных моделью логотипов.

Этот подход "Human-in-the-Loop" позволил в кратчайшие сроки получить высококачественный размеченный датасет.

## 7. Обучение финальной модели (YOLOv8s)

После доразметки был сформирован финальный датасет, который дополнительно был обогащен **негативными примерами** (изображения без логотипа) для повышения устойчивости модели.

Для обучения была выбрана модель **YOLOv8s ("small")** как оптимальный баланс между скоростью и точностью, полностью удовлетворяющий требованиям задачи. Обучение проводилось в среде Kaggle Notebooks с использованием двух GPU T4.

Финальная модель показала высокие метрики на валидационной выборке:
- **Precision:** ~0.94
- **Recall:** ~0.80
- **mAP50:** ~0.84

## 8. Создание REST API

Обученная модель (`best.pt`) была интегрирована в веб-сервис с использованием фреймворка **FastAPI**. Сервис предоставляет один эндпоинт `/detect`, который принимает изображение и возвращает JSON-ответ со списком координат найденных логотипов, строго соответствуя заданному контракту API.

### Скачивание артефактов

*   **Веса обученной модели (`best.pt`):** [ССЫЛКА НА ВАШИ ВЕСА НА GOOGLE DRIVE / HUGGING FACE]
*   **Валидационный набор данных:** [ССЫЛКА НА ВАШУ ПАПКУ validation_data НА GITHUB / GOOGLE DRIVE]

### Установка и запуск

**Пререквизиты:**
- Docker
- NVIDIA Container Toolkit (для запуска с GPU)

**Инструкция:**
1.  **Клонируйте репозиторий:**
    ```bash
    git clone [URL-вашего-репозитория]
    cd t_bank
    ```
2.  **Скачайте веса модели:**
    Скачайте файл `best.pt` по ссылке выше и поместите его в папку `weights/`.

3.  **Соберите Docker-образ:**
    ```bash
    docker build -t tbank-detector .
    ```

4.  **Запустите контейнер:**
    ```bash
    # Для запуска с использованием GPU
    docker run --gpus all -p 8000:8000 -d tbank-detector
    ```
    Сервис будет доступен по адресу `http://localhost:8000`. Для проверки работоспособности откройте в браузере `http://localhost:8000/docs`.
